{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.linalg import lstsq\n",
    "from numpy.linalg import pinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['yield', 'id', 'Row#'], axis=1)\n",
    "# X=df.drop('yield', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['yield']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressor=LassoCV(cv=5, random_state=0).fit(X_train, y_train)\n",
    "regressor=LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9187345540808263"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.6068705525308618\n",
      "17.12978511099368\n",
      "95.29292712886104\n",
      "13.70827130362426\n",
      "81.36851808167651\n",
      "5576.462575585038\n",
      "5213.768701194413\n",
      "-673.0527774662925\n",
      "-14.801445216996306\n",
      "-23360.79721187751\n",
      "-13.413460476760584\n",
      "4.174152392385878\n",
      "-471.4487122865894\n",
      "12916.971454761264\n",
      "-1504.2643868453692\n",
      "83.76388388149384\n"
     ]
    }
   ],
   "source": [
    "for coef in regressor.coef_:\n",
    "    print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly=PolynomialFeatures(degree=3).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262.22313984124867"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiVariateRegressor():\n",
    "    def __init__(self, degree):\n",
    "        self.degree = degree\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        self.B = None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        indices=np.random.shuffle(np.arange(X.shape[0]))\n",
    "        self.orig_X = X[indices][0]\n",
    "        self.Y = Y[indices][0]\n",
    "        self.X = X[indices][0]\n",
    "        self.X = np.hstack((np.ones((self.X.shape[0], 1)), self.X))\n",
    "        self.B = np.matmul(pinv(np.matmul(self.X.T, self.X)), np.matmul(self.X.T, self.Y))\n",
    "        # regres=LinearRegression(fit_intercept=False).fit(self.X, self.Y)\n",
    "        # for coef in zip(regres.coef_, self.B):\n",
    "        #     print(coef)\n",
    "\n",
    "    def generate_powers(self, x):\n",
    "        powers = [1]\n",
    "        for i in range(1, self.degree+1):\n",
    "            powers.append(powers[-1]*x)\n",
    "        return np.array(powers)\n",
    "    \n",
    "    def generate_sorted_vander(self, X, degree):\n",
    "        num_samples, num_features = X.shape \n",
    "        vander_matrix = [np.ones(num_samples)]\n",
    "        \n",
    "        for d in range(1, degree+1):\n",
    "            for indices in np.ndindex(*(num_features,)*d):\n",
    "                if sum(indices) == d:                \n",
    "                    vander_matrix.append(np.prod(X ** indices, axis=1))\n",
    "        return np.column_stack(vander_matrix)\n",
    "    \n",
    "    def predict_one(self, x):\n",
    "        return np.dot(self.generate_powers(x), self.B)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(np.hstack((np.ones((X.shape[0], 1)), X)), self.B)\n",
    "        vectorized_predict_one = np.vectorize(self.predict_one)\n",
    "        return vectorized_predict_one(X)\n",
    "\n",
    "    def sum_of_squares(self, Y_true, Y_pred):\n",
    "        return np.sum((Y_true - Y_pred)**2)\n",
    "        \n",
    "    def r2_score(self, Y_true, Y_pred):\n",
    "        # return np.sum((Y_true - Y_pred)**2)\n",
    "        return 1 - np.sum((Y_true - Y_pred)**2) / np.sum((Y_true - np.mean(Y_true))**2)\n",
    "\n",
    "    def k_fold_testing(self, k=10):\n",
    "        width = self.X.shape[0]//k\n",
    "        average_r2 = 0\n",
    "        count = 0\n",
    "        for i in range(0, self.X.shape[0], k):\n",
    "            count += 1\n",
    "            X_train = np.concatenate((self.X[:i], self.X[i+width:]))\n",
    "            Y_train = np.concatenate((self.Y[:i], self.Y[i+width:]))\n",
    "            X_test = self.X[i:i+width]\n",
    "            Y_test = self.Y[i:i+width]\n",
    "            B = np.matmul(np.linalg.inv(np.matmul(X_train.T, X_train)), np.matmul(X_train.T, Y_train))\n",
    "            predictions = np.matmul(X_test, B)\n",
    "            # average_r2 += r2_score(Y_test, predictions)\n",
    "            average_r2 += self.r2_score(Y_test, predictions)\n",
    "        B = np.matmul(np.linalg.inv(np.matmul(self.X.T, self.X)), np.matmul(self.X.T, self.Y))\n",
    "        return average_r2/count, np.matmul(self.X, B)\n",
    "    \n",
    "    def cross_validation(self, params):\n",
    "        maximum_param=np.max(params)\n",
    "        self.max_X=np.vander(self.orig_X, maximum_param+1, increasing=True)\n",
    "        responses = []\n",
    "        for param in params:\n",
    "            self.degree = param\n",
    "            self.X=self.max_X[:,:param+1]\n",
    "            response, plot_values = self.k_fold_testing()\n",
    "            responses.append(response)\n",
    "            # fig=plt.figure()\n",
    "            # plt.scatter(self.orig_X, self.Y)\n",
    "            # indices=np.argsort(self.orig_X)\n",
    "            # plt.plot(self.orig_X[indices], plot_values[indices], 'red')\n",
    "            # fig.savefig(f\"degree_{param}.png\")\n",
    "        print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=MultiVariateRegressor(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9187345697992927"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, reg.predict(X_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262.2232781809418"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, reg.predict(X_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output():\n",
    "    # X_all = np.vstack((X_train, X_test))\n",
    "    # y_all = np.concatenate((y_train, y_test))\n",
    "    reg.fit(np.vstack((X_train, X_test)), np.concatenate((y_train, y_test)))\n",
    "    test_data=pd.read_csv('test.csv')\n",
    "    X=test_data.drop(['id', 'Row#'], axis=1)\n",
    "    X=PolynomialFeatures(degree=2).fit_transform(X)\n",
    "    preds=reg.predict(X)\n",
    "    test_data['yield']=preds\n",
    "    test_data=test_data[['id', 'yield']]\n",
    "    test_data.to_csv('output.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = kde.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9187345540808263"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262.22313984124867"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.60687055e+00,  1.71297851e+01,  9.52929271e+01,  1.37082713e+01,\n",
       "        8.13685181e+01,  5.57646258e+03,  5.21376870e+03, -6.73052777e+02,\n",
       "       -1.48014452e+01, -2.33607972e+04, -1.34134605e+01,  4.17415239e+00,\n",
       "       -4.71448712e+02,  1.29169715e+04, -1.50426439e+03,  8.37638839e+01])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kde.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.90231332e+00,  1.40762086e+01, -6.07800130e+01, -5.59329633e+01,\n",
       "        7.54680576e+01, -7.20406858e+03, -6.14319839e+03, -2.28054561e+03,\n",
       "        8.95157011e+00,  3.68329640e+04, -7.60610148e+01,  9.46642987e+00,\n",
       "       -1.02912227e+03,  1.46331629e+04, -6.26779624e+03,  8.13053845e+01])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1.6068705525308618, -4.902313319034874)\n",
      "(17.12978511099368, 14.076208615791984)\n",
      "(95.29292712886104, -60.78001298010349)\n",
      "(13.70827130362426, -55.9329632781446)\n",
      "(81.36851808167651, 75.46805759519339)\n",
      "(5576.462575585038, -7204.06858253479)\n",
      "(5213.768701194413, -6143.1983852386475)\n",
      "(-673.0527774662925, -2280.545612215996)\n",
      "(-14.801445216996306, 8.951570108532906)\n",
      "(-23360.79721187751, 36832.96404647827)\n",
      "(-13.413460476760584, -76.06101481616497)\n",
      "(4.174152392385878, 9.466429865453392)\n",
      "(-471.4487122865894, -1029.12227293849)\n",
      "(12916.971454761264, 14633.162858784199)\n",
      "(-1504.2643868453692, -6267.796239495277)\n",
      "(83.76388388149384, 81.30538450879976)\n"
     ]
    }
   ],
   "source": [
    "for coef in zip(kde.coef_, regressor.B):\n",
    "    print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-10.634959249242108, -4.902313319034874)\n",
      "(3.7138845195848944, 14.076208615791984)\n",
      "(5.641474684876364, -60.78001298010349)\n",
      "(2.0100770397065872, -55.9329632781446)\n",
      "(11.682191180926282, 75.46805759519339)\n",
      "(50817.1556057072, -7204.06858253479)\n",
      "(28812.66593439402, -6143.1983852386475)\n",
      "(-5124.054559419127, -2280.545612215996)\n",
      "(-97.4832317294927, 8.951570108532906)\n",
      "(-74360.00371577418, 36832.96404647827)\n",
      "(-72.081111308513, -76.06101481616497)\n",
      "(49.375473076937226, 9.466429865453392)\n",
      "(-78.37846581793987, -1029.12227293849)\n",
      "(990.6356013384702, 14633.162858784199)\n",
      "(-57.36946245508608, -6267.796239495277)\n",
      "(343.35354152807116, 81.30538450879976)\n"
     ]
    }
   ],
   "source": [
    "for coef in zip(kde.coef_, regressor.B):\n",
    "    print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2=PolynomialFeatures(degree=2).fit_transform(X_train)\n",
    "X_test2=PolynomialFeatures(degree=2).fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = LinearRegression().fit(X_train3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262.2231398412343"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, kde.predict(X_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3=ss.transform(X_train)\n",
    "X_test3=ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9187345540808249"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, kde.predict(X_test3))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.048e+07, tolerance: 2.189e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: MAE = 269.7418799099052\n",
      "Ridge Regression: MAE = 272.18335295439056\n",
      "Lasso Regression: MAE = 275.59924082556154\n",
      "ElasticNet Regression: MAE = 351.35732948280616\n",
      "Random Forest: MAE = 261.89203582335915\n",
      "Gradient Boosting: MAE = 250.38153643448032\n",
      "AdaBoost Regressor: MAE = 412.6528484335456\n",
      "Support Vector Regression: MAE = 1016.4474512745328\n",
      "Decision Tree Regressor: MAE = 377.53323939666666\n",
      "K-Neighbors Regressor: MAE = 347.42687868\n",
      "Custom Regressor: MAE = 269.74190491481926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split your data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "# List of models to evaluate\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'ElasticNet Regression': ElasticNet(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'AdaBoost Regressor': AdaBoostRegressor(),\n",
    "    'Support Vector Regression': SVR(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(),\n",
    "    'K-Neighbors Regressor': KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "# Evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    results[name] = {'MAE': mae}\n",
    "\n",
    "# Fit your custom regressor\n",
    "reg.fit(X_train, y_train.values)\n",
    "predictions = reg.predict(X_test)\n",
    "results['Custom Regressor'] = {'MAE': mean_absolute_error(y_test, predictions)}\n",
    "\n",
    "# Display the results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: MAE = {metrics['MAE']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+09, tolerance: 2.189e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: MAE = 272.1912949141611\n",
      "Ridge Regression: MAE = 276.34054405664676\n",
      "Lasso Regression: MAE = 286.82496083118104\n",
      "ElasticNet Regression: MAE = 291.98583626180795\n",
      "Random Forest: MAE = 262.41807264920993\n",
      "Gradient Boosting: MAE = 250.0928636133857\n",
      "AdaBoost Regressor: MAE = 376.9815276545639\n",
      "Support Vector Regression: MAE = 1064.88014072126\n",
      "Decision Tree Regressor: MAE = 369.13922374\n",
      "K-Neighbors Regressor: MAE = 332.16913450199996\n",
      "Custom Regressor: MAE = 272.1912949094509\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split your data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train = X_train.values\n",
    "# X_test = X_test.values\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# X_train = PolynomialFeatures(degree=2).fit_transform(X_train)\n",
    "# X_test = PolynomialFeatures(degree=2).fit_transform(X_test)\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# ss=StandardScaler().fit(X_train)\n",
    "# # X_train=ss.transform(X_train)\n",
    "# # X_test=ss.transform(X_test)\n",
    "X_train=X_train[:, lasso_regressor.coef_ != 0]\n",
    "X_test=X_test[:, lasso_regressor.coef_ != 0]\n",
    "# List of models to evaluate\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'ElasticNet Regression': ElasticNet(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'AdaBoost Regressor': AdaBoostRegressor(),\n",
    "    'Support Vector Regression': SVR(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(),\n",
    "    'K-Neighbors Regressor': KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "# Evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    results[name] = {'MAE': mae}\n",
    "\n",
    "# Fit your custom regressor\n",
    "reg.fit(X_train, y_train.values)\n",
    "predictions = reg.predict(X_test)\n",
    "results['Custom Regressor'] = {'MAE': mean_absolute_error(y_test, predictions)}\n",
    "\n",
    "# Display the results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: MAE = {metrics['MAE']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: MAE = 270.2113776886595\n",
      "Ridge Regression: MAE = 269.48967952805043\n",
      "Lasso Regression: MAE = 270.9443636445984\n",
      "ElasticNet Regression: MAE = 293.1215223417799\n",
      "Random Forest: MAE = 262.0827522726089\n",
      "Gradient Boosting: MAE = 250.20869805098388\n",
      "AdaBoost Regressor: MAE = 379.67884740463194\n",
      "Support Vector Regression: MAE = 733.2060281254987\n",
      "Decision Tree Regressor: MAE = 374.4861873733333\n",
      "K-Neighbors Regressor: MAE = 359.207866724\n",
      "Custom Regressor: MAE = 269.63626413551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split your data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X_train = PolynomialFeatures(degree=2).fit_transform(X_train)\n",
    "X_test = PolynomialFeatures(degree=2).fit_transform(X_test)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler().fit(X_train)\n",
    "# X_train=ss.transform(X_train)\n",
    "# X_test=ss.transform(X_test)\n",
    "\n",
    "# List of models to evaluate\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'ElasticNet Regression': ElasticNet(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'AdaBoost Regressor': AdaBoostRegressor(),\n",
    "    'Support Vector Regression': SVR(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(),\n",
    "    'K-Neighbors Regressor': KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "# Evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    results[name] = {'MAE': mae}\n",
    "\n",
    "# Fit your custom regressor\n",
    "reg.fit(X_train, y_train.values)\n",
    "predictions = reg.predict(X_test)\n",
    "results['Custom Regressor'] = {'MAE': mean_absolute_error(y_test, predictions)}\n",
    "\n",
    "# Display the results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: MAE = {metrics['MAE']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train, y_train.values)\n",
    "predictions = reg.predict(X_test)\n",
    "results['Custom Regressor'] = {'MAE': mean_absolute_error(y_test, predictions)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_regressor=LassoCV(cv=5, random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-54.14244296508789, 6024.759223668327)\n",
      "(-0.21613085862132517, -291.1603576114285)\n",
      "(1080.5115281413478, 87.06694569255342)\n",
      "(107.77490325611852, 1344.069354611478)\n",
      "(-28.084439783639002, -44.630208914750256)\n",
      "(-0.2552188511842227, -19.288134651962537)\n",
      "(5.032552408092508, -1.480891664019964)\n",
      "(-2.537911648139373, 5.8726740401252755)\n",
      "(7.819160894141544, -17.50426606231258)\n",
      "(-8.647315189639444, 14.30190516337143)\n",
      "(3.3849725539192588, -15.242690700908497)\n",
      "(-16.472690067045765, 7.464691819624022)\n",
      "(30.015904858741685, -30.379559525024888)\n",
      "(16.145607616105753, 38.04968245529744)\n",
      "(-20.58284669928821, 235.52401351122535)\n",
      "(-70.84311245741726, 624.158798167482)\n",
      "(61.782089013794206, -1101.1216925410554)\n",
      "(-107.09956924342916, 222.95162866868486)\n",
      "(225.48153851641524, -112.29805905175704)\n"
     ]
    }
   ],
   "source": [
    "for coef_ in zip(lasso_regressor.coef_[np.where(lasso_regressor.coef_ != 0)], reg.B):\n",
    "    print(coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2=X_train[:,lasso_regressor.coef_ != 0]\n",
    "X_test2=X_test[:,lasso_regressor.coef_ != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 19) (12000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train2.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train2, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272.19129491395967"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, reg.predict(X_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
