{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.linalg import lstsq\n",
    "from numpy.linalg import pinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['yield', 'id', 'Row#'], axis=1)\n",
    "# X=df.drop('yield', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['yield']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressor=LassoCV(cv=5, random_state=0).fit(X_train, y_train)\n",
    "regressor=LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262.22313984124867"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.6068705525308618\n",
      "17.12978511099368\n",
      "95.29292712886104\n",
      "13.70827130362426\n",
      "81.36851808167651\n",
      "5576.462575585038\n",
      "5213.768701194413\n",
      "-673.0527774662925\n",
      "-14.801445216996306\n",
      "-23360.79721187751\n",
      "-13.413460476760584\n",
      "4.174152392385878\n",
      "-471.4487122865894\n",
      "12916.971454761264\n",
      "-1504.2643868453692\n",
      "83.76388388149384\n"
     ]
    }
   ],
   "source": [
    "for coef in regressor.coef_:\n",
    "    print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly=PolynomialFeatures(degree=3).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262.22313984124867"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=MultiVariateRegressor(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output():\n",
    "    # X_all = np.vstack((X_train, X_test))\n",
    "    # y_all = np.concatenate((y_train, y_test))\n",
    "    reg.fit(np.vstack((X_train, X_test)), np.concatenate((y_train, y_test)))\n",
    "    test_data=pd.read_csv('test.csv')\n",
    "    X=test_data.drop(['id', 'Row#'], axis=1)\n",
    "    X=PolynomialFeatures(degree=2).fit_transform(X)\n",
    "    preds=reg.predict(X)\n",
    "    test_data['yield']=preds\n",
    "    test_data=test_data[['id', 'yield']]\n",
    "    test_data.to_csv('output.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2=PolynomialFeatures(degree=2).fit_transform(X_train)\n",
    "X_test2=PolynomialFeatures(degree=2).fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.048e+07, tolerance: 2.189e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: MAE = 269.7418799099052\n",
      "Ridge Regression: MAE = 272.18335295439056\n",
      "Lasso Regression: MAE = 275.59924082556154\n",
      "ElasticNet Regression: MAE = 351.35732948280616\n",
      "Random Forest: MAE = 261.89203582335915\n",
      "Gradient Boosting: MAE = 250.38153643448032\n",
      "AdaBoost Regressor: MAE = 412.6528484335456\n",
      "Support Vector Regression: MAE = 1016.4474512745328\n",
      "Decision Tree Regressor: MAE = 377.53323939666666\n",
      "K-Neighbors Regressor: MAE = 347.42687868\n",
      "Custom Regressor: MAE = 269.74190491481926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split your data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "# List of models to evaluate\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'ElasticNet Regression': ElasticNet(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'AdaBoost Regressor': AdaBoostRegressor(),\n",
    "    'Support Vector Regression': SVR(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(),\n",
    "    'K-Neighbors Regressor': KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "# Evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    results[name] = {'MAE': mae}\n",
    "\n",
    "# Fit your custom regressor\n",
    "reg.fit(X_train, y_train.values)\n",
    "predictions = reg.predict(X_test)\n",
    "results['Custom Regressor'] = {'MAE': mean_absolute_error(y_test, predictions)}\n",
    "\n",
    "# Display the results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: MAE = {metrics['MAE']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+09, tolerance: 2.189e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: MAE = 272.1912949141611\n",
      "Ridge Regression: MAE = 276.34054405664676\n",
      "Lasso Regression: MAE = 286.82496083118104\n",
      "ElasticNet Regression: MAE = 291.98583626180795\n",
      "Random Forest: MAE = 262.41807264920993\n",
      "Gradient Boosting: MAE = 250.0928636133857\n",
      "AdaBoost Regressor: MAE = 376.9815276545639\n",
      "Support Vector Regression: MAE = 1064.88014072126\n",
      "Decision Tree Regressor: MAE = 369.13922374\n",
      "K-Neighbors Regressor: MAE = 332.16913450199996\n",
      "Custom Regressor: MAE = 272.1912949094509\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split your data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train = X_train.values\n",
    "# X_test = X_test.values\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# X_train = PolynomialFeatures(degree=2).fit_transform(X_train)\n",
    "# X_test = PolynomialFeatures(degree=2).fit_transform(X_test)\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# ss=StandardScaler().fit(X_train)\n",
    "# # X_train=ss.transform(X_train)\n",
    "# # X_test=ss.transform(X_test)\n",
    "X_train=X_train[:, lasso_regressor.coef_ != 0]\n",
    "X_test=X_test[:, lasso_regressor.coef_ != 0]\n",
    "# List of models to evaluate\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'ElasticNet Regression': ElasticNet(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'AdaBoost Regressor': AdaBoostRegressor(),\n",
    "    'Support Vector Regression': SVR(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(),\n",
    "    'K-Neighbors Regressor': KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "# Evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    results[name] = {'MAE': mae}\n",
    "\n",
    "# Fit your custom regressor\n",
    "reg.fit(X_train, y_train.values)\n",
    "predictions = reg.predict(X_test)\n",
    "results['Custom Regressor'] = {'MAE': mean_absolute_error(y_test, predictions)}\n",
    "\n",
    "# Display the results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: MAE = {metrics['MAE']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: MAE = 270.2113776886595\n",
      "Ridge Regression: MAE = 269.48967952805043\n",
      "Lasso Regression: MAE = 270.9443636445984\n",
      "ElasticNet Regression: MAE = 293.1215223417799\n",
      "Random Forest: MAE = 262.0827522726089\n",
      "Gradient Boosting: MAE = 250.20869805098388\n",
      "AdaBoost Regressor: MAE = 379.67884740463194\n",
      "Support Vector Regression: MAE = 733.2060281254987\n",
      "Decision Tree Regressor: MAE = 374.4861873733333\n",
      "K-Neighbors Regressor: MAE = 359.207866724\n",
      "Custom Regressor: MAE = 269.63626413551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split your data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X_train = PolynomialFeatures(degree=2).fit_transform(X_train)\n",
    "X_test = PolynomialFeatures(degree=2).fit_transform(X_test)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler().fit(X_train)\n",
    "# X_train=ss.transform(X_train)\n",
    "# X_test=ss.transform(X_test)\n",
    "\n",
    "# List of models to evaluate\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'ElasticNet Regression': ElasticNet(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'AdaBoost Regressor': AdaBoostRegressor(),\n",
    "    'Support Vector Regression': SVR(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(),\n",
    "    'K-Neighbors Regressor': KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "# Evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    results[name] = {'MAE': mae}\n",
    "\n",
    "# Fit your custom regressor\n",
    "reg.fit(X_train, y_train.values)\n",
    "predictions = reg.predict(X_test)\n",
    "results['Custom Regressor'] = {'MAE': mean_absolute_error(y_test, predictions)}\n",
    "\n",
    "# Display the results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: MAE = {metrics['MAE']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.745e+08, tolerance: 2.189e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/aditya/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+09, tolerance: 2.189e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: MAE = 269.7490002936198\n",
      "Ridge Regression: MAE = 270.59842777289595\n",
      "Lasso Regression: MAE = 270.93308816269473\n",
      "ElasticNet Regression: MAE = 275.85288887865073\n",
      "Random Forest: MAE = 261.6784511464501\n",
      "Gradient Boosting: MAE = 250.3433723756168\n",
      "AdaBoost Regressor: MAE = 385.558457364837\n",
      "Support Vector Regression: MAE = 1012.4855689604067\n",
      "Decision Tree Regressor: MAE = 363.8743066033333\n",
      "K-Neighbors Regressor: MAE = 348.1337413473334\n",
      "Custom Regressor: MAE = 97778.18424961988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split your data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X_train = PolynomialFeatures(degree=2).fit_transform(X_train)\n",
    "X_test = PolynomialFeatures(degree=2).fit_transform(X_test)\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# ss=StandardScaler().fit(X_train)\n",
    "# X_train=ss.transform(X_train)\n",
    "# X_test=ss.transform(X_test)\n",
    "\n",
    "# List of models to evaluate\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'ElasticNet Regression': ElasticNet(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'AdaBoost Regressor': AdaBoostRegressor(),\n",
    "    'Support Vector Regression': SVR(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(),\n",
    "    'K-Neighbors Regressor': KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "# Evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    results[name] = {'MAE': mae}\n",
    "\n",
    "# Fit your custom regressor\n",
    "reg.fit(X_train, y_train.values)\n",
    "predictions = reg.predict(X_test)\n",
    "results['Custom Regressor'] = {'MAE': mean_absolute_error(y_test, predictions)}\n",
    "\n",
    "# Display the results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: MAE = {metrics['MAE']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: MAE = 266.97935716333336\n",
      "Ridge Regression: MAE = 269.2385631741124\n",
      "Lasso Regression: MAE = 270.6749871269195\n",
      "ElasticNet Regression: MAE = 275.58386600766835\n",
      "Random Forest: MAE = 261.64038838632865\n",
      "Gradient Boosting: MAE = 249.90628230139555\n",
      "AdaBoost Regressor: MAE = 366.48049992199884\n",
      "Support Vector Regression: MAE = 1010.7589034764919\n",
      "Decision Tree Regressor: MAE = 368.68010102\n",
      "K-Neighbors Regressor: MAE = 347.91271330666666\n",
      "Custom Regressor: MAE = 92642.79238900472\n"
     ]
    }
   ],
   "source": [
    "reg.fit(X_train, y_train.values)\n",
    "predictions = reg.predict(X_test)\n",
    "results['Custom Regressor'] = {'MAE': mean_absolute_error(y_test, predictions)}\n",
    "\n",
    "# Display the results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: MAE = {metrics['MAE']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.86184992e+00,  6.68396298e+10, -9.01675189e+08, -6.37117170e+08,\n",
       "       -1.73688178e+09, -4.08976854e+10, -2.01482601e+10, -2.36792794e+10,\n",
       "       -3.04032182e+10, -6.42728051e+09, -1.36061324e+10, -5.01307991e+10,\n",
       "       -9.34353550e+08,  7.73426699e+08,  3.46865957e+08,  3.99024898e+10,\n",
       "        5.50420891e-02,  5.62833305e-01,  8.99651843e+00,  2.40440974e+00,\n",
       "       -2.07426819e+11, -7.64970871e+11, -9.54851855e+10,  9.23028346e+11,\n",
       "        4.01287564e+11, -9.54851855e+10,  1.24122720e+00, -8.73760327e+01,\n",
       "       -1.28915120e+02,  1.45207895e+01,  2.21393706e+00,  2.10033848e+03,\n",
       "       -3.21308968e+02, -1.09686914e+02,  1.26790728e+09, -8.82601546e+09,\n",
       "        1.28810373e+09,  3.63320803e+09, -1.08316070e+09,  1.28810463e+09,\n",
       "        1.96716309e+01, -1.54146341e+03, -5.12832917e+03,  3.39606367e+03,\n",
       "        7.39439087e+01, -4.52206097e+01, -4.79889256e+02,  9.10917433e+08,\n",
       "       -1.96270411e+09,  9.10167540e+08, -1.67646740e+09,  5.54073159e+08,\n",
       "        9.10168703e+08, -7.06085968e+00,  2.39004914e+02,  7.57974664e+02,\n",
       "       -1.31903908e+03,  2.28279114e+00, -1.43397808e+02,  2.21152925e+09,\n",
       "       -2.94591570e+10,  2.48125873e+09,  1.89946544e+10, -4.62324904e+09,\n",
       "        2.48125837e+09,  2.32612305e+01, -1.42917811e+03,  1.03244252e+03,\n",
       "       -3.21621714e+03,  5.10404091e+01, -6.46234665e+10, -1.41064305e+10,\n",
       "        8.80002840e+10, -1.89183171e+10,  7.38584292e+10,  6.53362940e+10,\n",
       "        8.19213345e+10,  1.47390428e+09, -1.35517710e+09, -6.37855904e+08,\n",
       "       -7.16371333e+10,  5.95875666e+10, -1.44888701e+10,  8.92288491e+10,\n",
       "        5.96102481e+10, -1.52625428e+10, -1.93804997e+11, -3.37267601e+09,\n",
       "        4.16774535e+08,  9.55722402e+08,  6.60862158e+10, -5.89053558e+10,\n",
       "        2.50125449e+10,  7.14556517e+10,  2.65064886e+10,  7.16154961e+10,\n",
       "        1.33061030e+09, -1.10482985e+09, -4.95514020e+08, -5.70035578e+10,\n",
       "       -2.75187659e+11,  5.96129720e+10,  3.85664428e+10, -7.20453103e+10,\n",
       "       -1.66313925e+09,  3.50177941e+09,  7.41895222e+08,  1.32660863e+11,\n",
       "        6.53105239e+10,  6.83143567e+10, -4.12552064e+10, -3.53204853e+08,\n",
       "        4.18410359e+08,  6.53754562e+08,  4.84590261e+10, -8.34149431e+10,\n",
       "        7.16154962e+10,  1.33060447e+09, -1.10483860e+09, -4.95502007e+08,\n",
       "       -5.70035577e+10,  7.70544098e+03, -1.03878834e+06,  4.55061386e+02,\n",
       "       -2.70026703e+01, -4.67485809e+00,  3.46922989e+07, -2.45029293e+04,\n",
       "       -8.32521017e+03,  3.09237747e+02,  1.24386423e+04, -2.12430322e+04,\n",
       "       -7.99312592e+02, -1.24532234e+04,  6.61984728e+02,  8.42500305e+00])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearRegression().fit(X_train, y_train).coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train, y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.95942656e+16,  6.95939346e+16,  2.93792799e+09, -3.63685106e+10,\n",
       "       -1.23096415e+11,  6.23305730e+10,  1.14762200e+11,  3.12566193e+11,\n",
       "       -6.92081934e+10, -3.43271649e+10, -4.79722304e+11, -7.73292331e+10,\n",
       "        2.94858975e+08, -8.91977263e+10,  7.89579991e+10, -4.43175270e+10,\n",
       "       -5.47238197e+08,  3.76456418e+01,  2.19638243e+04,  4.10575143e+03,\n",
       "       -6.10603708e+03, -4.52034055e+09,  6.30322401e+08, -4.19704341e+09,\n",
       "        1.55113130e+10, -3.12317053e+09, -4.19693418e+09, -1.70166166e+02,\n",
       "        9.78193599e+03,  6.20072810e+04, -9.72977261e+04, -3.65781487e+02,\n",
       "        4.98320971e+06, -2.68417148e+06, -1.19038646e+06,  4.31399259e+10,\n",
       "       -4.31355703e+11,  5.19781503e+10,  2.06023342e+11, -1.31341231e+10,\n",
       "        5.19720321e+10,  2.63930064e+05, -1.91791600e+07, -3.74786322e+06,\n",
       "       -2.79567951e+06,  8.18462916e+04, -1.00775297e+06,  4.73508725e+05,\n",
       "        3.27099965e+11, -2.43467693e+11,  1.75851875e+11, -1.57464563e+11,\n",
       "       -9.05373576e+11,  1.75848031e+11, -4.11625901e+04,  3.06365184e+06,\n",
       "       -1.65822878e+05,  5.52612048e+06, -3.81594134e+04,  2.69668396e+05,\n",
       "       -9.40691870e+10,  2.50353184e+11, -8.90427650e+10,  9.57597158e+10,\n",
       "       -7.87788216e+07, -8.90415140e+10,  2.08292382e+04, -1.54607994e+06,\n",
       "        6.72294584e+05, -5.50671916e+06,  3.10729865e+04,  8.07637343e+08,\n",
       "       -1.01816888e+09,  1.84693812e+09, -3.54537597e+09, -2.76595018e+09,\n",
       "       -1.22021239e+08,  1.61599659e+09,  1.72702132e+11, -2.39163492e+11,\n",
       "        4.16696451e+09,  2.64851081e+09, -3.81322827e+09,  3.34923219e+06,\n",
       "        2.37980580e+09, -1.45186072e+09,  3.32524682e+08,  2.42442469e+09,\n",
       "        3.41369062e+10,  1.23205843e+11,  5.10595950e+10,  1.04112052e+09,\n",
       "       -2.07968943e+09,  1.56342622e+09, -2.20280654e+09,  1.94737898e+09,\n",
       "       -4.21288460e+08,  1.27429947e+11, -1.12798761e+11,  6.33267718e+10,\n",
       "        7.81655793e+08, -2.59838445e+08,  2.72293576e+09, -2.24670558e+09,\n",
       "        3.33568210e+09, -4.53339983e+11,  7.52573760e+10, -4.22614313e+11,\n",
       "       -4.34656132e+08,  1.45281850e+10,  9.19663655e+09, -1.40154073e+10,\n",
       "       -1.35559512e+11,  7.75228411e+11,  5.15439317e+11, -1.16776035e+10,\n",
       "       -2.04704286e+09, -4.21262586e+08,  1.27428163e+11, -1.12798840e+11,\n",
       "        6.33184402e+10,  7.81747178e+08,  8.52144488e+02, -1.15615651e+05,\n",
       "        4.53347615e+02, -2.62109709e+01, -4.65028735e+00,  3.87616892e+06,\n",
       "       -2.44959648e+04, -8.28581327e+03,  3.09839428e+02,  1.24363712e+04,\n",
       "       -2.12371530e+04, -7.99319841e+02, -1.24460627e+04,  6.54841411e+02,\n",
       "        8.55469649e+00])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstsq(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_regressor=LassoCV(cv=5, random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-54.14244296508789, 6024.759223668327)\n",
      "(-0.21613085862132517, -291.1603576114285)\n",
      "(1080.5115281413478, 87.06694569255342)\n",
      "(107.77490325611852, 1344.069354611478)\n",
      "(-28.084439783639002, -44.630208914750256)\n",
      "(-0.2552188511842227, -19.288134651962537)\n",
      "(5.032552408092508, -1.480891664019964)\n",
      "(-2.537911648139373, 5.8726740401252755)\n",
      "(7.819160894141544, -17.50426606231258)\n",
      "(-8.647315189639444, 14.30190516337143)\n",
      "(3.3849725539192588, -15.242690700908497)\n",
      "(-16.472690067045765, 7.464691819624022)\n",
      "(30.015904858741685, -30.379559525024888)\n",
      "(16.145607616105753, 38.04968245529744)\n",
      "(-20.58284669928821, 235.52401351122535)\n",
      "(-70.84311245741726, 624.158798167482)\n",
      "(61.782089013794206, -1101.1216925410554)\n",
      "(-107.09956924342916, 222.95162866868486)\n",
      "(225.48153851641524, -112.29805905175704)\n"
     ]
    }
   ],
   "source": [
    "for coef_ in zip(lasso_regressor.coef_[np.where(lasso_regressor.coef_ != 0)], reg.B):\n",
    "    print(coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2=X_train[:,lasso_regressor.coef_ != 0]\n",
    "X_test2=X_test[:,lasso_regressor.coef_ != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 19) (12000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train2.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train2, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272.19129491395967"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, reg.predict(X_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
