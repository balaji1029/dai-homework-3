{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as pt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Row#</th>\n",
       "      <th>clonesize</th>\n",
       "      <th>honeybee</th>\n",
       "      <th>bumbles</th>\n",
       "      <th>andrena</th>\n",
       "      <th>osmia</th>\n",
       "      <th>MaxOfUpperTRange</th>\n",
       "      <th>MinOfUpperTRange</th>\n",
       "      <th>AverageOfUpperTRange</th>\n",
       "      <th>MaxOfLowerTRange</th>\n",
       "      <th>MinOfLowerTRange</th>\n",
       "      <th>AverageOfLowerTRange</th>\n",
       "      <th>RainingDays</th>\n",
       "      <th>AverageRainingDays</th>\n",
       "      <th>fruitset</th>\n",
       "      <th>fruitmass</th>\n",
       "      <th>seeds</th>\n",
       "      <th>yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.63</td>\n",
       "      <td>94.6</td>\n",
       "      <td>57.2</td>\n",
       "      <td>79.0</td>\n",
       "      <td>68.2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>55.9</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.402948</td>\n",
       "      <td>0.409261</td>\n",
       "      <td>31.274591</td>\n",
       "      <td>4418.44126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>124.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>77.4</td>\n",
       "      <td>46.8</td>\n",
       "      <td>64.7</td>\n",
       "      <td>55.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.500438</td>\n",
       "      <td>0.445494</td>\n",
       "      <td>34.467567</td>\n",
       "      <td>5862.80545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>485.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.75</td>\n",
       "      <td>94.6</td>\n",
       "      <td>57.2</td>\n",
       "      <td>79.0</td>\n",
       "      <td>68.2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>55.9</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.509001</td>\n",
       "      <td>0.459421</td>\n",
       "      <td>36.624966</td>\n",
       "      <td>6079.08526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>324.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>94.6</td>\n",
       "      <td>57.2</td>\n",
       "      <td>79.0</td>\n",
       "      <td>68.2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>55.9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.583379</td>\n",
       "      <td>0.498056</td>\n",
       "      <td>40.865478</td>\n",
       "      <td>7400.77538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>235.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.63</td>\n",
       "      <td>77.4</td>\n",
       "      <td>46.8</td>\n",
       "      <td>64.7</td>\n",
       "      <td>55.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.447669</td>\n",
       "      <td>0.423764</td>\n",
       "      <td>33.298861</td>\n",
       "      <td>4858.24073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   Row#  clonesize  honeybee  bumbles  andrena  osmia  MaxOfUpperTRange  \\\n",
       "0   0  639.0       25.0      0.50     0.25     0.75   0.63              94.6   \n",
       "1   1  124.0       12.5      0.25     0.25     0.25   0.25              77.4   \n",
       "2   2  485.0       25.0      0.50     0.25     0.38   0.75              94.6   \n",
       "3   3  324.0       12.5      0.25     0.25     0.75   0.75              94.6   \n",
       "4   4  235.0       12.5      0.25     0.25     0.50   0.63              77.4   \n",
       "\n",
       "   MinOfUpperTRange  AverageOfUpperTRange  MaxOfLowerTRange  MinOfLowerTRange  \\\n",
       "0              57.2                  79.0              68.2              33.0   \n",
       "1              46.8                  64.7              55.8              27.0   \n",
       "2              57.2                  79.0              68.2              33.0   \n",
       "3              57.2                  79.0              68.2              33.0   \n",
       "4              46.8                  64.7              55.8              27.0   \n",
       "\n",
       "   AverageOfLowerTRange  RainingDays  AverageRainingDays  fruitset  fruitmass  \\\n",
       "0                  55.9         34.0                0.56  0.402948   0.409261   \n",
       "1                  45.8         34.0                0.56  0.500438   0.445494   \n",
       "2                  55.9         24.0                0.39  0.509001   0.459421   \n",
       "3                  55.9         16.0                0.26  0.583379   0.498056   \n",
       "4                  45.8         24.0                0.39  0.447669   0.423764   \n",
       "\n",
       "       seeds       yield  \n",
       "0  31.274591  4418.44126  \n",
       "1  34.467567  5862.80545  \n",
       "2  36.624966  6079.08526  \n",
       "3  40.865478  7400.77538  \n",
       "4  33.298861  4858.24073  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ads = pd.read_csv('train.csv')\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "print(input_ads.shape)\n",
    "input_ads.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 16)\n",
      "(3000, 16)\n",
      "(12000, 1)\n"
     ]
    }
   ],
   "source": [
    "X = input_ads.drop(['yield', 'id', 'Row#'], axis=1)\n",
    "y = input_ads['yield']\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Scaling the datasets\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_arr = scaler.fit_transform(X)\n",
    "X_test_arr = scaler.fit_transform(X_test)\n",
    "\n",
    "y_arr = np.array(y).reshape(X_arr.shape[0],1)\n",
    "y_test_arr = np.array(y_test).reshape(X_test_arr.shape[0],1)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "print(X_arr.shape)\n",
    "print(X_test_arr.shape)\n",
    "print(y_arr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "#Loss func\n",
    "def loss_calc(y_true,y_pred):\n",
    "    \n",
    "    loss = np.sum(np.abs(y_true-y_pred))\n",
    "        \n",
    "    return loss\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "#Gradient Calc\n",
    "def gradient_calc(y_true,y_pred):\n",
    "    \n",
    "    grad = -(y_true-y_pred)\n",
    "    \n",
    "    return grad\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "#The base estimator\n",
    "def tree_creator(r_state,X,y):\n",
    "    \n",
    "    d_tree = DecisionTreeRegressor(random_state=r_state,criterion='absolute_error',\n",
    "                                    max_depth=2,min_samples_split=5,\n",
    "                                    min_samples_leaf=5,max_features=3)\n",
    "    d_tree.fit(X,y)\n",
    "    \n",
    "    return d_tree\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "#Predicting through gradient boosting regression\n",
    "def predict_grad_boost(models_tray,alpha,test_x=X_test_arr,train_y=y_arr):\n",
    "    \n",
    "    initial_pred = np.array([np.mean(train_y)] * len(test_x))\n",
    "        \n",
    "    final_pred = initial_pred.reshape(len(initial_pred),1)\n",
    "    #print(final_pred.shape)\n",
    "    \n",
    "    for i in range(len(models_tray)):\n",
    "        \n",
    "        model = models_tray[i]\n",
    "        temp_pred = (model.predict(test_x)).reshape(len(test_x),1)\n",
    "        #print(temp_pred.shape)\n",
    "        final_pred -= alpha * temp_pred\n",
    "    \n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_boost_train(train_x,train_y,alpha=0.01,r_state=100,n_iters=101):\n",
    "\n",
    "    model_tray = [] #Tray to collect the trained boosted stage estimators\n",
    "    loss_counter = [] #Tray for loss capture\n",
    "\n",
    "    \n",
    "    initial_pred = np.array([np.mean(train_y)] * len(train_y))\n",
    "\n",
    "    print('Initial val :',initial_pred.shape)\n",
    "    model_pred = initial_pred.reshape(len(initial_pred),1)\n",
    "\n",
    "    for epoch in range(n_iters): #Unit iteration\n",
    "\n",
    "        if epoch%100==0:\n",
    "            print('#---------- Epoch number :',epoch,' -----------#')\n",
    "        \n",
    "        #Calculating loss\n",
    "        loss = loss_calc(y_true=train_y,\n",
    "                         y_pred=model_pred)\n",
    "\n",
    "        loss_counter.append(loss)\n",
    "        \n",
    "        #Calculating the gradient (residuals)\n",
    "        grads = gradient_calc(y_true=train_y,\n",
    "                              y_pred=model_pred)\n",
    "        #print(grads.shape)\n",
    "        #Building the regression tree on the gradient (residuals)\n",
    "        tree_grad = tree_creator(r_state=r_state,\n",
    "                                 X=train_x,\n",
    "                                 y=grads)\n",
    "        #print(train_x.shape)\n",
    "        #print(tree_grad.predict(train_x).shape)\n",
    "        \n",
    "        #Predicting the residuals according to the tree fit above\n",
    "        pred_m = (tree_grad.predict(train_x)).reshape(len(train_x),1)\n",
    "        \n",
    "        #Updating model through learning rate\n",
    "        model_pred -= alpha * pred_m\n",
    "        \n",
    "        #Appending the model into tray\n",
    "        model_tray.append(tree_grad)\n",
    "        \n",
    "    return model_tray,loss_counter,initial_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial val : (12000,)\n",
      "#---------- Epoch number : 0  -----------#\n",
      "#---------- Epoch number : 100  -----------#\n",
      "#---------- Epoch number : 200  -----------#\n",
      "#---------- Epoch number : 300  -----------#\n",
      "#---------- Epoch number : 400  -----------#\n",
      "#---------- Epoch number : 500  -----------#\n",
      "#---------- Epoch number : 600  -----------#\n",
      "#---------- Epoch number : 700  -----------#\n",
      "#---------- Epoch number : 800  -----------#\n",
      "#---------- Epoch number : 900  -----------#\n",
      "#---------- Epoch number : 1000  -----------#\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 1001 #No of boosting steps\n",
    "alpha =0.01 #Learning rate\n",
    "\n",
    "#Training gradient boosting regression\n",
    "models_list,loss_counter,initial_pred = grad_boost_train(train_x=X_arr,\n",
    "                                                         train_y=y_arr,\n",
    "                                                         alpha=alpha,\n",
    "                                                         r_state=100,\n",
    "                                                         n_iters=n_estimators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_gbm_pred = predict_grad_boost(models_tray=models_list, #Passing the fitted estimators into the predict function\n",
    "                                     alpha=alpha, #The alpha val used during training\n",
    "                                     test_x=X_test_arr) #Test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635.9315321445847"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test_arr,manual_gbm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "skl_gbm = GradientBoostingRegressor(random_state=100,n_estimators=1001,criterion='squared_error',\n",
    "                                    max_depth=2,min_samples_split=5,\n",
    "                                    min_samples_leaf=5,max_features=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/.local/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(criterion=&#x27;squared_error&#x27;, max_depth=2,\n",
       "                          max_features=3, min_samples_leaf=5,\n",
       "                          min_samples_split=5, n_estimators=1001,\n",
       "                          random_state=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(criterion=&#x27;squared_error&#x27;, max_depth=2,\n",
       "                          max_features=3, min_samples_leaf=5,\n",
       "                          min_samples_split=5, n_estimators=1001,\n",
       "                          random_state=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(criterion='squared_error', max_depth=2,\n",
       "                          max_features=3, min_samples_leaf=5,\n",
       "                          min_samples_split=5, n_estimators=1001,\n",
       "                          random_state=100)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl_gbm.fit(X_arr,y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_pred = skl_gbm.predict(X_test_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261.6564010870834"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test_arr,skl_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class GradientBoostingRegressor:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "\n",
    "    def _mse_split(self, X, y, feature_index, threshold):\n",
    "        left_mask = X[:, feature_index] <= threshold\n",
    "        right_mask = ~left_mask\n",
    "        return left_mask, right_mask\n",
    "\n",
    "    def _fit_tree(self, X, y):\n",
    "        best_split = None\n",
    "        best_mse = float('inf')\n",
    "        best_left, best_right = None, None\n",
    "\n",
    "        for feature_index in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "            for threshold in thresholds:\n",
    "                left_mask, right_mask = self._mse_split(X, y, feature_index, threshold)\n",
    "                if len(y[left_mask]) == 0 or len(y[right_mask]) == 0:\n",
    "                    continue\n",
    "\n",
    "                left_error = np.var(y[left_mask]) * len(y[left_mask])\n",
    "                right_error = np.var(y[right_mask]) * len(y[right_mask])\n",
    "                mse = left_error + right_error\n",
    "\n",
    "                if mse < best_mse:\n",
    "                    best_mse = mse\n",
    "                    best_split = (feature_index, threshold)\n",
    "                    best_left, best_right = left_mask, right_mask\n",
    "\n",
    "        return best_split, best_left, best_right\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if depth == self.max_depth or len(np.unique(y)) == 1:\n",
    "            return np.mean(y)\n",
    "\n",
    "        split, left_mask, right_mask = self._fit_tree(X, y)\n",
    "        if split is None:\n",
    "            return np.mean(y)\n",
    "\n",
    "        left_subtree = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        right_subtree = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "\n",
    "        return (split, left_subtree, right_subtree)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.initial_prediction = np.mean(y)\n",
    "        residuals = y - self.initial_prediction\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            tree = self._build_tree(X, residuals, depth=0)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "            predictions = self._predict_tree(tree, X)\n",
    "            residuals -= self.learning_rate * predictions\n",
    "\n",
    "    def _predict_tree(self, tree, X):\n",
    "        if not isinstance(tree, tuple):\n",
    "            return np.full(X.shape[0], tree)\n",
    "\n",
    "        feature_index, threshold = tree[0]\n",
    "        left_mask = X[:, feature_index] <= threshold\n",
    "        right_mask = ~left_mask\n",
    "\n",
    "        predictions = np.zeros(X.shape[0])\n",
    "        predictions[left_mask] = self._predict_tree(tree[1], X[left_mask])\n",
    "        predictions[right_mask] = self._predict_tree(tree[2], X[right_mask])\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.full(X.shape[0], self.initial_prediction)\n",
    "\n",
    "        for tree in self.trees:\n",
    "            predictions += self.learning_rate * self._predict_tree(tree, X)\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m gbr \u001b[38;5;241m=\u001b[39m GradientBoostingRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Fit the model on the training data\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m gbr\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Predict on the test data\u001b[39;00m\n\u001b[1;32m      8\u001b[0m predictions \u001b[38;5;241m=\u001b[39m gbr\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "\n",
    "# Fit the model on the training data\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "predictions = gbr.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE)\n",
    "mae = np.mean(np.abs(y_test - predictions))\n",
    "print(f\"Mean Absolute Error: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['yield', 'id', 'Row#'],axis=1)\n",
    "y=df['yield']\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HigherOrderRegressor():\n",
    "    def __init__(self, degree):\n",
    "        self.degree = degree\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        self.B = None\n",
    "        self.num_features = None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        if len(Y.shape) == 1:\n",
    "            Y = Y.reshape(-1, 1)\n",
    "        self.num_features=X.shape[1]\n",
    "        indices=np.random.shuffle(np.arange(X.shape[0]))\n",
    "        temp_X = X[indices][0]\n",
    "        temp_Y = Y[indices][0]\n",
    "        # np.hstack((np.ones((self.X.shape[0], 1)), self.X))\n",
    "        self.orig_X = np.hstack((np.ones((X.shape[0], 1)), temp_X))\n",
    "        self.Y = temp_Y\n",
    "        self.X = self.recursive_generate_powers(0, self.degree, np.ones(X.shape[0])).T\n",
    "        try:\n",
    "            self.B = np.matmul(np.linalg.pinv(np.matmul(self.X.T, self.X)),\n",
    "                                np.matmul(self.X.T, self.Y))\n",
    "        except:\n",
    "            self.B = np.matmul(np.linalg.pinv(np.matmul(self.X.T, self.X)),\n",
    "                                np.matmul(self.X.T, self.Y))\n",
    "\n",
    "    def recursive_generate_powers(self, max_feature_encountered, current_degree, current_product, use_orig=True):\n",
    "        if current_degree == 0:\n",
    "            return current_product\n",
    "        result=[]\n",
    "        for i in range(max_feature_encountered, self.num_features+1):\n",
    "            if use_orig:\n",
    "                result.append(self.recursive_generate_powers(i, current_degree-1,\n",
    "                                                            current_product*self.orig_X[:,i]))\n",
    "            else:\n",
    "                result.append(self.recursive_generate_powers(i, current_degree-1,\n",
    "                                                            current_product*self.test_X[:,i], False))\n",
    "        result=np.vstack(result)\n",
    "        return result\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1,1)\n",
    "        self.test_X=np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        self.final_testX=self.recursive_generate_powers(0, self.degree, np.ones(X.shape[0]), False).T\n",
    "        return np.matmul(self.final_testX, self.B)\n",
    "\n",
    "    def sum_of_squares(self, Y_true, Y_pred):\n",
    "        return np.sum((Y_true - Y_pred)**2)\n",
    "        \n",
    "    def r2_score(self, Y_true, Y_pred):\n",
    "        return 1 - np.sum((Y_true - Y_pred)**2) / np.sum((Y_true - np.mean(Y_true))**2)\n",
    "\n",
    "    def k_fold_testing(self, k=10):\n",
    "        width = self.X.shape[0]//k\n",
    "        average_r2 = 0\n",
    "        count = 0\n",
    "        for i in range(0, self.X.shape[0], k):\n",
    "            count += 1\n",
    "            X_train = np.concatenate((self.X[:i], self.X[i+width:]))\n",
    "            Y_train = np.concatenate((self.Y[:i], self.Y[i+width:]))\n",
    "            X_test = self.X[i:i+width]\n",
    "            Y_test = self.Y[i:i+width]\n",
    "            try:\n",
    "                B = np.matmul(np.linalg.pinv(np.matmul(X_train.T, X_train)), np.matmul(X_train.T, Y_train))\n",
    "            except:\n",
    "                B = np.matmul(np.linalg.pinv(np.matmul(X_train.T, X_train)), np.matmul(X_train.T, Y_train))\n",
    "            predictions = np.matmul(X_test, B)\n",
    "            average_r2 += self.r2_score(Y_test, predictions)\n",
    "        # print(self.X.shape)\n",
    "        try:\n",
    "            B = np.matmul(np.linalg.pinv(np.matmul(self.X.T, self.X)), np.matmul(self.X.T, self.Y))\n",
    "        except:\n",
    "            B = np.matmul(np.linalg.pinv(np.matmul(self.X.T, self.X)), np.matmul(self.X.T, self.Y))\n",
    "        return average_r2/count, np.matmul(self.X, B)\n",
    "    \n",
    "    def cross_validation(self, params):\n",
    "        maximum_param=np.max(params)\n",
    "        self.max_X=self.recursive_generate_powers(0, maximum_param, np.ones(self.X.shape[0])).T\n",
    "        # print(self.max_X)\n",
    "        responses = []\n",
    "        factorials=[1]\n",
    "        for i in range(1, maximum_param+self.num_features+1):\n",
    "            factorials.append(factorials[-1]*i)\n",
    "        for param in params:\n",
    "            self.degree = param\n",
    "            # print((factorials[param+self.num_features]//factorials[self.num_features])//factorials[param])\n",
    "            self.X=self.max_X[:,:(factorials[param+self.num_features]//factorials[self.num_features])//factorials[param]]\n",
    "            response, plot_values = self.k_fold_testing()\n",
    "            responses.append(response)\n",
    "            fig=plt.figure()\n",
    "            plt.scatter(self.orig_X[:,1], self.Y)\n",
    "            indices=np.argsort(self.orig_X[:,1])\n",
    "            plt.plot(self.orig_X[:,1][indices], plot_values[indices], 'red')\n",
    "            fig.savefig(f\"degree_{param}.png\")\n",
    "        print(responses)\n",
    "    \n",
    "    def write_params(self):\n",
    "        with open(\"3_weights.pkl\", \"wb\") as f:\n",
    "            pickle.dump(self.B, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=HigherOrderRegressor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train=X_train.values\n",
    "X_test=X_test.values\n",
    "y_train=y_train.values\n",
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269.74188837706777"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65535/65535 [04:01<00:00, 271.36it/s]\n"
     ]
    }
   ],
   "source": [
    "errors=[]\n",
    "for i in tqdm(range(1, 2**16)):\n",
    "    mask = np.array(list(np.binary_repr(i, width=16)), dtype=int).astype(bool)\n",
    "    X_train2=X_train[:,mask]\n",
    "    X_test2=X_test[:,mask]\n",
    "    X_train2=PolynomialFeatures(degree=1).fit_transform(X_train2)\n",
    "    X_test2=PolynomialFeatures(degree=1).fit_transform(X_test2)\n",
    "    reg.fit(X_train2, y_train)\n",
    "    errors.append(mean_absolute_error(y_test, reg.predict(X_test2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19146/19146 [13:06<00:00, 24.33it/s]\n"
     ]
    }
   ],
   "source": [
    "errors=[]\n",
    "for i in tqdm(range(46390, 2**16)):\n",
    "    mask = np.array(list(np.binary_repr(i, width=16)), dtype=int).astype(bool)\n",
    "    X_train2=X_train[:,mask]\n",
    "    X_test2=X_test[:,mask]\n",
    "    X_train2=PolynomialFeatures(degree=2).fit_transform(X_train2)\n",
    "    X_test2=PolynomialFeatures(degree=2).fit_transform(X_test2)\n",
    "    reg.fit(X_train2, y_train)\n",
    "    errors.append(mean_absolute_error(y_test, reg.predict(X_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265.4839192082926\n"
     ]
    }
   ],
   "source": [
    "print(np.min(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5534\n"
     ]
    }
   ],
   "source": [
    "print(np.argmin(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266.1416372492567\n"
     ]
    }
   ],
   "source": [
    "print(np.min(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585\n"
     ]
    }
   ],
   "source": [
    "print(np.argmin(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262.75726659899703"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.array(list(np.binary_repr(5535, width=16)), dtype=int).astype(bool)\n",
    "X_train2=X_train[:,mask]\n",
    "X_test2=X_test[:,mask]\n",
    "X_train2=PolynomialFeatures(degree=3).fit_transform(X_train2)\n",
    "X_test2=PolynomialFeatures(degree=3).fit_transform(X_test2)\n",
    "reg.fit(X_train2, y_train)\n",
    "mean_absolute_error(y_test, reg.predict(X_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Row#', 'clonesize', 'honeybee', 'bumbles', 'andrena', 'osmia',\n",
       "       'MaxOfUpperTRange', 'MinOfUpperTRange', 'AverageOfUpperTRange',\n",
       "       'MaxOfLowerTRange', 'MinOfLowerTRange', 'AverageOfLowerTRange',\n",
       "       'RainingDays', 'AverageRainingDays', 'fruitset', 'fruitmass', 'seeds',\n",
       "       'yield'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final=test_data.drop(['id', 'Row#'],axis=1)\n",
    "X_test_final=X_test_final.values[:,mask]\n",
    "X_test_final=PolynomialFeatures(degree=4).fit_transform(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['yield']=reg.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_new=test_data[['id', 'yield']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_new.to_csv('hello.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_preds=pd.read_csv('output.csv')['yield']\n",
    "new_preds=pd.read_csv('hello.csv')['yield']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.11148719824867"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(orig_preds, new_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%history -g -f second_file.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1637.70402"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data=pd.read_csv('train.csv')\n",
    "np.min(data['yield'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
